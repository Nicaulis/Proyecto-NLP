{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ-VfNtOyJbsaxu43Kztf_cv1mgBG6ZIQZEVw&usqp=CAU'>\n",
    "\n",
    "   ##   Procesamiento de Lenguage Natural\n",
    "   ###  Taller #2: Adquisición de textos\n",
    "   ###  Docente: Viviana Marquez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1\n",
    "\n",
    "- Descomprimir el archivo .zip de los poemas\n",
    "- Leer cada uno de sus archivos\n",
    "- Responder: ¿Cuál archivo tiene el mayor número de palabras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El archivo\n",
    "archivo_zip = zipfile.ZipFile(\"C:/Users/practicas/Documents/poemas.zip\", \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poemas/',\n",
       " 'poemas/Si╠ündrome (Mario Benedetti).txt',\n",
       " '__MACOSX/poemas/._Si╠ündrome (Mario Benedetti).txt',\n",
       " 'poemas/A un general (Julio Corta╠üzar).txt',\n",
       " '__MACOSX/poemas/._A un general (Julio Corta╠üzar).txt',\n",
       " 'poemas/Aqui╠ü (Octavio Paz).txt',\n",
       " '__MACOSX/poemas/._Aqui╠ü (Octavio Paz).txt']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descomprimier el archivo\n",
    "archivo_zip.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todavía tengo casi todos mis dientes\n",
      "\n",
      "casi todos mis cabellos y poquísimas canas\n",
      "\n",
      "puedo hacer y deshacer el amor\n",
      "\n",
      "trepar una escalera de dos en dos\n",
      "\n",
      "y correr cuarenta metros detrás del ómnibus\n",
      "\n",
      "o sea que no debería sentirme viejo\n",
      "\n",
      "pero el grave problema es que antes\n",
      "\n",
      "no me fijaba en estos detalles.\n"
     ]
    }
   ],
   "source": [
    "# leer el archivo\n",
    "mario = archivo_zip.open(archivo_zip.namelist()[1]).read().decode(\"utf-8\")\n",
    "print(mario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Región de manos sucias de pinceles sin pelo\n",
      "\n",
      "de niños boca abajo de cepillos de dientes\n",
      "\n",
      "Zona donde la rata se ennoblece\n",
      "\n",
      "y hay banderas innúmeras y cantan himnos\n",
      "\n",
      "y alguien te prende, hijo de puta,\n",
      "\n",
      "una medalla sobre el pecho\n",
      "\n",
      "Y te pudres lo mismo.\n"
     ]
    }
   ],
   "source": [
    "octavio = archivo_zip.open(archivo_zip.namelist()[3]).read().decode(\"utf-8\")\n",
    "print(octavio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis pasos en esta calle\n",
      "\n",
      "Resuenan\n",
      "\n",
      "En otra calle\n",
      "\n",
      "Donde\n",
      "\n",
      "Oigo mis pasos\n",
      "\n",
      "Pasar en esta calle\n",
      "\n",
      "Donde\n",
      "\n",
      "Sólo es real la niebla.\n"
     ]
    }
   ],
   "source": [
    "cortazar = archivo_zip.open(archivo_zip.namelist()[5]).read().decode(\"utf-8\")\n",
    "print(cortazar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mario Benedetti tiene 53 palabras en su poema\n",
      "Octavio Paz tiene 46 palabras en su poema\n",
      "Julio Cortázar 23 palabras en su poema\n"
     ]
    }
   ],
   "source": [
    "#Contar palabras\n",
    "print(\"Mario Benedetti tiene\",len(mario.split()),\"palabras en su poema\")\n",
    "print(\"Octavio Paz tiene\",len(octavio.split()),\"palabras en su poema\")\n",
    "print(\"Julio Cortázar\",len(cortazar.split()),\"palabras en su poema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El archivo que contiene mayor numero de palabras es el poema de Mario Benedetti 53\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2\n",
    "\n",
    "- Hacer Web Scraping de 10 biografías en Wikipedia (en búcle)\n",
    "- Obtener el encabezado de cada biografía\n",
    "- Obtener todos los contenidos y etiquetas de título asociados a los links del primer párrafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_1 = \"https://es.wikipedia.org/wiki/Celia_Cruz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Celia Cruz']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_1)\n",
    "Origen1 = request.read()\n",
    "request.close\n",
    "Celia_Cruz = bs.BeautifulSoup(Origen1,'html.parser')\n",
    "for etiqueta1 in Celia_Cruz.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La Habana']\n",
      "['Cuba']\n",
      "['21 de octubre']\n",
      "['1925']\n",
      "['Fort Lee']\n",
      "['Nueva Jersey']\n",
      "['Estados Unidos']\n",
      "['16 de julio']\n",
      "['2003']\n",
      "[<span class=\"corchete-llamada\">[</span>, '1', <span class=\"corchete-llamada\">]</span>]\n",
      "['cantante']\n",
      "['cubana']\n",
      "['música tropical']\n",
      "[<span class=\"corchete-llamada\">[</span>, '2', <span class=\"corchete-llamada\">]</span>]\n",
      "[<span class=\"corchete-llamada\">[</span>, '3', <span class=\"corchete-llamada\">]</span>]\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Celia_Cruz.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_2 = \"https://es.wikipedia.org/wiki/Ismael_Rivera\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ismael Rivera']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_2)\n",
    "Origen2 = request.read()\n",
    "request.close\n",
    "Ismael_Rivera = bs.BeautifulSoup(Origen2,'html.parser')\n",
    "for etiqueta1 in Ismael_Rivera.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Santurce']\n",
      "['5 de octubre']\n",
      "['1931']\n",
      "['13 de mayo']\n",
      "['1987']\n",
      "['puertorriqueño']\n",
      "['Tite Curet Alonso']\n",
      "['Portobelo']\n",
      "['Panamá']\n",
      "[<span class=\"corchete-llamada\">[</span>, '1', <span class=\"corchete-llamada\">]</span>]\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Ismael_Rivera.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_3 = \"https://es.wikipedia.org/wiki/Cheo_Feliciano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cheo Feliciano']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_3)\n",
    "Origen3 = request.read()\n",
    "request.close\n",
    "Cheo_Feliciano = bs.BeautifulSoup(Origen3,'html.parser')\n",
    "for etiqueta1 in Cheo_Feliciano.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ponce']\n",
      "['San Juan']\n",
      "[<span class=\"corchete-llamada\">[</span>, '1', <span class=\"corchete-llamada\">]</span>]\n",
      "['cantante']\n",
      "['músico']\n",
      "['puertorriqueño']\n",
      "['salsa']\n",
      "['bolero']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Cheo_Feliciano.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_4 = \"https://es.wikipedia.org/wiki/Ismael_Miranda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ismael Miranda']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_4)\n",
    "Origen4 = request.read()\n",
    "request.close\n",
    "Ismael_Miranda = bs.BeautifulSoup(Origen4,'html.parser')\n",
    "for etiqueta1 in Ismael_Miranda.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aguada']\n",
      "['20 de febrero']\n",
      "['1950']\n",
      "['salsa']\n",
      "[<span class=\"corchete-llamada\">[</span>, '1', <span class=\"corchete-llamada\">]</span>]\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Ismael_Miranda.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_5 = \"https://es.wikipedia.org/wiki/Bobby_Valentin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bobby Valentin']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_5)\n",
    "Origen5 = request.read()\n",
    "request.close\n",
    "Bobby_Valentin = bs.BeautifulSoup(Origen5,'html.parser')\n",
    "for etiqueta1 in Bobby_Valentin.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bajista']\n",
      "['director de orquesta']\n",
      "['puertorriqueño']\n",
      "['Salsa']\n",
      "['Latin Jazz']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Bobby_Valentin.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_6 = \"https://es.wikipedia.org/wiki/Roberto_Roena\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Roberto Roena']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_6)\n",
    "Origen6 = request.read()\n",
    "request.close\n",
    "Roberto_Roena = bs.BeautifulSoup(Origen6,'html.parser')\n",
    "for etiqueta1 in Roberto_Roena.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16 de enero']\n",
      "['1940']\n",
      "[<span class=\"corchete-llamada\">[</span>, '1', <span class=\"corchete-llamada\">]</span>]\n",
      "['Mayagüez']\n",
      "['Puerto Rico']\n",
      "[' bongosero ']\n",
      "['salsa']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Roberto_Roena.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_7 = \"https://es.wikipedia.org/wiki/El_Gran_Combo_de_Puerto_Rico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El Gran Combo de Puerto Rico']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_7)\n",
    "Origen7 = request.read()\n",
    "request.close\n",
    "El_Gran_Combo_de_Puerto_Rico = bs.BeautifulSoup(Origen7,'html.parser')\n",
    "for etiqueta1 in El_Gran_Combo_de_Puerto_Rico.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salsa']\n",
      "['Puerto Rico']\n",
      "['América Latina']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = El_Gran_Combo_de_Puerto_Rico.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_8 = \"https://es.wikipedia.org/wiki/Gilberto_Santa_Rosa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gilberto Santa Rosa']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_8)\n",
    "Origen8 = request.read()\n",
    "request.close\n",
    "Gilberto_Santa_Rosa = bs.BeautifulSoup(Origen8,'html.parser')\n",
    "for etiqueta1 in Gilberto_Santa_Rosa.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Santurce']\n",
      "['Puerto Rico']\n",
      "['21 de agosto']\n",
      "['1962']\n",
      "['actor']\n",
      "['cantante']\n",
      "['salsa']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Gilberto_Santa_Rosa.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_9 = \"https://es.wikipedia.org/wiki/Marc_Anthony\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marc Anthony']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_9)\n",
    "Origen9 = request.read()\n",
    "request.close\n",
    "Marc_Anthony = bs.BeautifulSoup(Origen9,'html.parser')\n",
    "for etiqueta1 in Marc_Anthony.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nueva York']\n",
      "['16 de septiembre']\n",
      "['1968']\n",
      "['cantante']\n",
      "['actor']\n",
      "['estadounidense']\n",
      "['salsa']\n",
      "['bolero']\n",
      "['balada']\n",
      "['pop']\n",
      "['hip hop']\n",
      "['Ralph Mercado']\n",
      "['Hasta que te conocí']\n",
      "['Juan Gabriel']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Marc_Anthony.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biblio_10 = \"https://es.wikipedia.org/wiki/Grupo_Niche\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grupo Niche']\n"
     ]
    }
   ],
   "source": [
    "request = urllib.request.urlopen(Biblio_10)\n",
    "Origen10 = request.read()\n",
    "request.close\n",
    "Grupo_Niche = bs.BeautifulSoup(Origen10,'html.parser')\n",
    "for etiqueta1 in Grupo_Niche.find_all('h1'):\n",
    "    print(etiqueta1.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salsa']\n",
      "['Bogotá']\n",
      "['Colombia']\n",
      "['Jairo Varela']\n",
      "['Alexis Lozano']\n",
      "[<span class=\"corchete-llamada\">[</span>, '1', <span class=\"corchete-llamada\">]</span>]\n",
      "['Cali']\n"
     ]
    }
   ],
   "source": [
    "parrafo_1 = Grupo_Niche.p\n",
    "for etiquetasp1 in parrafo_1.find_all('a'):\n",
    "    print(etiquetasp1.contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
